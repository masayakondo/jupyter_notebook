{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"RTE_with_LSTM.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"h_ve-NdsLSip","colab_type":"code","outputId":"21e41c99-a861-4abd-d5c5-358420f2af19","executionInfo":{"status":"ok","timestamp":1575427273147,"user_tz":-540,"elapsed":34636,"user":{"displayName":"M K","photoUrl":"","userId":"05537230611998731047"}},"colab":{"base_uri":"https://localhost:8080/","height":122}},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n","\n","Enter your authorization code:\n","··········\n","Mounted at /content/drive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"lAHfizRWy1f0","colab_type":"code","colab":{}},"source":["!apt install aptitude\n","!aptitude install mecab libmecab-dev mecab-ipadic-utf8 git make curl xz-utils file -y\n","!pip install mecab-python3"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"QXqdYPP5ACyd","colab_type":"code","colab":{}},"source":["import torchtext\n","from torchtext import data\n","from torchtext import datasets\n","from torchtext.vocab import GloVe\n","from torchtext.vocab import FastText\n","from torchtext.vocab import Vectors\n","\n","import torch.nn as nn\n","import torch.optim as optim\n","import torch.nn.functional as F\n","import torch\n","from torch.autograd import Variable\n","\n","import pickle\n","\n","import numpy as np\n","from keras.utils import np_utils\n","\n","import re, os\n","from glob import glob\n","from sklearn.model_selection import train_test_split\n","from tqdm import tqdm\n","import linecache\n","import pandas as pd"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"vxyEzO1Xy6hi","colab_type":"code","colab":{}},"source":["import MeCab\n","import re\n","\n","tagger = MeCab.Tagger(\"-Owakati\")\n","\n","def make_wakati(sentence):\n","    sentence = tagger.parse(sentence)\n","    sentence = re.sub(r'[0-9０-９a-zA-Zａ-ｚＡ-Ｚ]+', \" \", sentence)\n","    sentence = re.sub(r'[\\．_－―─！＠＃＄％＾＆\\-‐|\\\\＊\\“（）＿■×+α※÷⇒—●★☆〇◎◆▼◇△□(：〜～＋=)／*&^%$#@!~`){}［］…\\[\\]\\\"\\'\\”\\’:;<>?＜＞〔〕〈〉？、。・,\\./『』【】「」→←○《》≪≫\\n\\u3000]+', \"\", sentence)\n","    wakati = sentence.split(\" \")\n","    wakati = list(filter((\"\").__ne__, wakati))\n","    return wakati"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"q3TFLvPbHuaA","colab_type":"code","colab":{}},"source":["# import nltk\n","# from nltk import stem\n","# nltk.download('all')\n","\n","# def nltk_analyzer(text):\n","#   stemmer = stem.LancasterStemmer()\n","#   text = re.sub(re.compile(r'[!-\\/:-@[-`{-~]'), ' ', text)\n","#   text = stemmer.stem(text)\n","#   text = text.replace('\\n', '') # 改行削除\n","#   text = text.replace('\\t', '') # タブ削除\n","#   morph = nltk.word_tokenize(text)\n","#   return morph"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"b6qY2JD9zGGq","colab_type":"code","colab":{}},"source":["drive_dir = \"drive/My Drive/Colab Notebooks/rte/\"\n","datasets = pd.read_csv(drive_dir + 'Translation_of_SNLI.csv')\n","train_df, test_df = train_test_split(datasets, train_size=0.95)\n","\n","col = [\"sentence1\", \"sentence2\", \"gold_id\"]\n","\n","labels = [\"contradiction\", \"entailment\", \"neutral\", \"-\"]\n","\n","\n","\n","\n","# def concat_df(df):\n","#   label_ids = []\n","#   for label in df['gold_label']:\n","#     idx = labels.index(label)\n","#     label_ids.append(idx)\n","#   join_df = pd.DataFrame(label_ids, columns=['gold_id'])\n","#   print(len(df), len(join_df))\n","#   return pd.concat([df, join_df], axis=1)\n","\n","# train_df = concat_df(train_df)\n","# test_df = concat_df(test_df)\n","\n","# rm y label \"-\" line and fillna\n","# train_df = train_df[train_df[\"gold_label\"] != \"-\"].fillna(\"\")\n","# test_df = test_df[test_df[\"gold_label\"] != \"-\"].fillna(\"\")"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"qZ0MzquL1xki","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":606},"outputId":"3ab9e2b7-2f01-4dd7-a353-65487925f58a","executionInfo":{"status":"ok","timestamp":1575430119051,"user_tz":-540,"elapsed":768,"user":{"displayName":"M K","photoUrl":"","userId":"05537230611998731047"}}},"source":["train_df"],"execution_count":71,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Unnamed: 0</th>\n","      <th>gold_label</th>\n","      <th>t1_en</th>\n","      <th>t2_en</th>\n","      <th>t1_jp</th>\n","      <th>t2_jp</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>162176</th>\n","      <td>162176</td>\n","      <td>neutral</td>\n","      <td>A man in a white jacket walks underneath a bri...</td>\n","      <td>He is homeless and trying to get to his box to...</td>\n","      <td>白いジャケットを着た男性が橋の下を歩き、光線で強調されます。</td>\n","      <td>彼はホームレスで、自分の箱に寝ようとしています。</td>\n","    </tr>\n","    <tr>\n","      <th>253354</th>\n","      <td>253354</td>\n","      <td>entailment</td>\n","      <td>Three people look up at a man on a ladder agai...</td>\n","      <td>hree people look up at a man on a ladder.</td>\n","      <td>3人がレンガの壁に向かってはしごの男を見上げます。</td>\n","      <td>3人がはしごの男を見上げます。</td>\n","    </tr>\n","    <tr>\n","      <th>106650</th>\n","      <td>106650</td>\n","      <td>entailment</td>\n","      <td>A group of people on a crowded sidewalk boardi...</td>\n","      <td>A group of people are getting on a bus.</td>\n","      <td>2階建てバスに乗る混雑した歩道上の人々のグループ。</td>\n","      <td>人々のグループがバスに乗っています。</td>\n","    </tr>\n","    <tr>\n","      <th>373023</th>\n","      <td>373023</td>\n","      <td>contradiction</td>\n","      <td>Vendors in Europe, a man and a woman preparing...</td>\n","      <td>A man and woman are selling fruits and vegetab...</td>\n","      <td>ヨーロッパのベンダー、野菜と果物を販売する日のために準備する男女。</td>\n","      <td>男性と女性がアメリカで果物と野菜を販売しています。</td>\n","    </tr>\n","    <tr>\n","      <th>124924</th>\n","      <td>124924</td>\n","      <td>contradiction</td>\n","      <td>The little girl is picking up the beans.</td>\n","      <td>a little girl throws away some food</td>\n","      <td>小さな女の子は豆を拾っています。</td>\n","      <td>小さな女の子が食べ物を捨てる</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>199449</th>\n","      <td>199449</td>\n","      <td>entailment</td>\n","      <td>Many people gathered outside, sitting on bench...</td>\n","      <td>Many people gathered outside, sitting on bench...</td>\n","      <td>多くの人々が外に集まり、ベンチや草の中に座っていました。</td>\n","      <td>多くの人々が外に集まり、外のベンチに座っていました。</td>\n","    </tr>\n","    <tr>\n","      <th>55746</th>\n","      <td>55746</td>\n","      <td>entailment</td>\n","      <td>A man with a race number on his shirt running ...</td>\n","      <td>There is a man running</td>\n","      <td>ベビーカーで小さな女の子と実行している彼のシャツにレース番号を持つ男。</td>\n","      <td>走っている男がいる</td>\n","    </tr>\n","    <tr>\n","      <th>268541</th>\n","      <td>268541</td>\n","      <td>contradiction</td>\n","      <td>Blond girl paying with a hula hoop.</td>\n","      <td>The girls are taking a math test.</td>\n","      <td>フラフープで支払うブロンドの女の子。</td>\n","      <td>女の子は数学のテストを受けています。</td>\n","    </tr>\n","    <tr>\n","      <th>503362</th>\n","      <td>503362</td>\n","      <td>entailment</td>\n","      <td>A craftsman thoughtfully considers his designs...</td>\n","      <td>A craftsman is thinking about his designs.</td>\n","      <td>職人は、ワークショップで自分のデザインを熟考します。</td>\n","      <td>職人は自分のデザインについて考えています。</td>\n","    </tr>\n","    <tr>\n","      <th>374115</th>\n","      <td>374115</td>\n","      <td>contradiction</td>\n","      <td>Seven children dressed for cold weather on a b...</td>\n","      <td>The children are sitting in a classroom.</td>\n","      <td>ユーロが使用されているレンガの道で寒い気候に身を包んだ7人の子供たち。</td>\n","      <td>子供たちは教室に座っています。</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>516948 rows × 6 columns</p>\n","</div>"],"text/plain":["        Unnamed: 0  ...                       t2_jp\n","162176      162176  ...    彼はホームレスで、自分の箱に寝ようとしています。\n","253354      253354  ...             3人がはしごの男を見上げます。\n","106650      106650  ...          人々のグループがバスに乗っています。\n","373023      373023  ...   男性と女性がアメリカで果物と野菜を販売しています。\n","124924      124924  ...              小さな女の子が食べ物を捨てる\n","...            ...  ...                         ...\n","199449      199449  ...  多くの人々が外に集まり、外のベンチに座っていました。\n","55746        55746  ...                   走っている男がいる\n","268541      268541  ...          女の子は数学のテストを受けています。\n","503362      503362  ...       職人は自分のデザインについて考えています。\n","374115      374115  ...             子供たちは教室に座っています。\n","\n","[516948 rows x 6 columns]"]},"metadata":{"tags":[]},"execution_count":71}]},{"cell_type":"code","metadata":{"id":"3nowTEYmANYP","colab_type":"code","colab":{}},"source":["drive_dir = \"drive/My Drive/Colab Notebooks/rte/\"\n","train_df = pd.read_csv(drive_dir + \"snli_1.0_train.txt\", sep=\"\\t\", header=0)\n","val_df = pd.read_csv(drive_dir + \"snli_1.0_dev.txt\", sep=\"\\t\", header=0)\n","test_df = pd.read_csv(drive_dir + \"snli_1.0_test.txt\", sep=\"\\t\", header=0)\n","\n","col = [\"sentence1\", \"sentence2\", \"gold_id\"]\n","\n","labels = [\"contradiction\", \"entailment\", \"neutral\", \"-\"]\n","\n","def concat_df(df):\n","  label_ids = []\n","  for label in df['gold_label']:\n","    idx = labels.index(label)\n","    label_ids.append(idx)\n","  join_df = pd.DataFrame(label_ids, columns=['gold_id'])\n","  return pd.concat([df, join_df], axis=1)\n","\n","train_df = concat_df(train_df)\n","val_df = concat_df(val_df)\n","test_df = concat_df(test_df)\n","\n","# rm y label \"-\" line and fillna\n","train_df = train_df[train_df[\"gold_label\"] != \"-\"].fillna(\"\")\n","val_df = val_df[val_df[\"gold_label\"] != \"-\"].fillna(\"\")\n","test_df = test_df[test_df[\"gold_label\"] != \"-\"].fillna(\"\")\n","\n","train_df[col].to_csv(drive_dir + \"train.tsv\", sep=\"\\t\", index=None, header=False)\n","val_df[col].to_csv(drive_dir + \"val.tsv\", sep=\"\\t\", index=None, header=False)\n","test_df[col].to_csv(drive_dir + \"test.tsv\", sep=\"\\t\", index=None, header=False)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"QEAw-zCFGYi8","colab_type":"code","colab":{}},"source":["TEXT = data.Field(sequential=True, tokenize=make_wakati, lower=True, include_lengths=True, batch_first=True)\n","LABEL = data.Field(sequential=False, use_vocab=False, is_target=True)\n","  \n","train, val, test = data.TabularDataset.splits(\n","      path=drive_dir, train='train.tsv',\n","      validation='val.tsv', test='test.tsv', format='tsv',\n","      fields=[('Text1', TEXT), ('Text2', TEXT), ('Label', LABEL)])"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"1CjwegcdUqWn","colab_type":"code","outputId":"2de5e2c2-79e4-4196-a4fc-51280aa1eade","executionInfo":{"status":"ok","timestamp":1575364568256,"user_tz":-540,"elapsed":53769,"user":{"displayName":"M K","photoUrl":"","userId":"05537230611998731047"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["glove_vectors = Vectors(name=drive_dir + \"glove.6B.200d.txt\")\n","TEXT.build_vocab(train, val, test, vectors=glove_vectors, min_freq=1)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["100%|█████████▉| 399404/400000 [00:34<00:00, 11775.11it/s]"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"rQYbFhlAYXDc","colab_type":"code","colab":{}},"source":["device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","train_iter, val_iter, test_iter = data.Iterator.splits((train, val, test), batch_sizes=(100, 100, 100), device=device, repeat=False, sort=False)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"W9uc_tSejqJP","colab_type":"code","outputId":"b42ac0d0-de9c-42a2-b27a-df36bdae917f","executionInfo":{"status":"ok","timestamp":1575364574906,"user_tz":-540,"elapsed":649,"user":{"displayName":"M K","photoUrl":"","userId":"05537230611998731047"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["TEXT.vocab.vectors.size()[0]"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["34463"]},"metadata":{"tags":[]},"execution_count":8}]},{"cell_type":"code","metadata":{"id":"Yohj7T87bxsf","colab_type":"code","outputId":"5bf4c556-31d1-4ba0-8c27-00accbe547e6","executionInfo":{"status":"ok","timestamp":1575364585542,"user_tz":-540,"elapsed":6624,"user":{"displayName":"M K","photoUrl":"","userId":"05537230611998731047"}},"colab":{"base_uri":"https://localhost:8080/","height":71}},"source":["import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import torch.optim as optim\n","\n","class LSTMEmbedding(nn.Module):\n","  def __init__(self, embedding_dim, lstm_dim, vocab_size):\n","    super(LSTMEmbedding, self).__init__()\n","    self.lstm_dim = lstm_dim\n","    self.word_embeddings = nn.Embedding(vocab_size, embedding_dim)\n","    self.word_embeddings.weight.data.copy_(TEXT.vocab.vectors)\n","    self.word_embeddings.requires_grad_ = False    \n","    self.lstm = nn.LSTM(embedding_dim, lstm_dim, batch_first=True, dropout=0.5)\n","  \n","  def forward(self, text):\n","    embeds = self.word_embeddings(text)\n","    _, state = self.lstm(embeds)\n","    return state[0]\n","\n","\n","class MergeLSTM(nn.Module):\n","  def __init__(self, lstm_dim, hidden_dim, tagset_size):\n","    super(MergeLSTM, self).__init__()\n","    self.lstm_dim = lstm_dim\n","    self.hidden_dim = hidden_dim\n","    self.tagset_size = tagset_size\n","    self.softmax = nn.Softmax(dim=1)\n","    self.main = nn.Sequential(\n","        nn.BatchNorm1d(self.lstm_dim*2),\n","\n","        nn.Linear(self.lstm_dim*2, self.hidden_dim),\n","        nn.PReLU(),\n","        nn.Dropout(0.5),\n","        nn.BatchNorm1d(self.hidden_dim),\n","        \n","        nn.Linear(self.hidden_dim, self.hidden_dim),\n","        nn.PReLU(),\n","        nn.Dropout(0.5),\n","        nn.BatchNorm1d(self.hidden_dim),\n","\n","        nn.Linear(self.hidden_dim, self.hidden_dim),\n","        nn.PReLU(),\n","        nn.Dropout(0.5),\n","        nn.BatchNorm1d(self.hidden_dim),\n","        \n","        nn.Linear(self.hidden_dim, tagset_size)\n","    )\n","\n","    \n","  def forward(self, state1, state2):\n","    state = torch.cat([state1, state2], dim=1)\n","    hidden = self.main(state)\n","    tag_score = self.softmax(hidden)\n","    return tag_score\n","\n","EMBEDDING_DIM = 200\n","LSTM_DIM = 200\n","HIDDEN_DIM = 300\n","VOCAB_SIZE = TEXT.vocab.vectors.size()[0]\n","TAG_SIZE = 3\n","\n","# to(device)でモデルがGPU対応する\n","model1 = LSTMEmbedding(EMBEDDING_DIM, LSTM_DIM, VOCAB_SIZE).to(device)\n","model2 = LSTMEmbedding(EMBEDDING_DIM, LSTM_DIM, VOCAB_SIZE).to(device)\n","merge = MergeLSTM(LSTM_DIM, HIDDEN_DIM, TAG_SIZE).to(device)\n","\n","# loss_function = nn.NLLLoss()\n","loss_function = nn.CrossEntropyLoss()\n","model1_optimizer = optim.Adam(model1.parameters(), lr=0.001)\n","model2_optimizer = optim.Adam(model2.parameters(), lr=0.001)\n","merge_optimizer = optim.Adam(merge.parameters(), lr=0.001)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/torch/nn/modules/rnn.py:51: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.5 and num_layers=1\n","  \"num_layers={}\".format(dropout, num_layers))\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"JzP94NTUgjTW","colab_type":"code","outputId":"fcaa1a8a-b873-478d-b1e0-7af33a8b9624","executionInfo":{"status":"error","timestamp":1575369005012,"user_tz":-540,"elapsed":4416281,"user":{"displayName":"M K","photoUrl":"","userId":"05537230611998731047"}},"colab":{"base_uri":"https://localhost:8080/","height":780}},"source":["losses = []\n","for epoch in range(100):\n","  all_loss = 0\n","\n","  for idx, batch in enumerate(train_iter):\n","    batch_loss = 0\n","    model1.zero_grad()\n","    model2.zero_grad()\n","    merge.zero_grad()\n","    \n","    text1_tensor = batch.Text1[0]\n","    text2_tensor = batch.Text2[0]\n","    label_tensor = batch.Label\n","\n","    state1 = model1(text1_tensor).squeeze()\n","    state2 = model2(text2_tensor).squeeze()\n","    score = merge(state1, state2)\n","\n","    batch_loss = loss_function(score, label_tensor)\n","    batch_loss.backward()\n","    model1_optimizer.step()\n","    model2_optimizer.step()\n","    merge_optimizer.step()\n","    \n","    all_loss += batch_loss.item()\n","  print(\"epoch\", epoch, \"\\t\" , \"loss\", all_loss)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["epoch 0 \t loss 4996.707608103752\n","epoch 1 \t loss 4735.979795217514\n","epoch 2 \t loss 4603.145826458931\n","epoch 3 \t loss 4485.0309846401215\n","epoch 4 \t loss 4394.917196214199\n","epoch 5 \t loss 4333.4020909667015\n","epoch 6 \t loss 4281.546170771122\n","epoch 7 \t loss 4239.057874262333\n","epoch 8 \t loss 4200.856141209602\n","epoch 9 \t loss 4169.181241154671\n","epoch 10 \t loss 4144.0787162184715\n","epoch 11 \t loss 4119.282353520393\n","epoch 12 \t loss 4098.843482255936\n","epoch 13 \t loss 4082.2214800715446\n","epoch 14 \t loss 4063.7675580978394\n","epoch 15 \t loss 4050.0937114953995\n","epoch 16 \t loss 4032.4641233086586\n","epoch 17 \t loss 4020.55526971817\n","epoch 18 \t loss 4013.0062601566315\n","epoch 19 \t loss 4000.9986991882324\n","epoch 20 \t loss 3987.029092490673\n","epoch 21 \t loss 3977.382672905922\n","epoch 22 \t loss 3973.0348151922226\n","epoch 23 \t loss 3963.71888846159\n","epoch 24 \t loss 3955.0785363316536\n"],"name":"stdout"},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-10-150570f1f972>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     21\u001b[0m     \u001b[0mmodel1_optimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m     \u001b[0mmodel2_optimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m     \u001b[0mmerge_optimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m     \u001b[0mall_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mbatch_loss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/optim/adam.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, closure)\u001b[0m\n\u001b[1;32m    101\u001b[0m                     \u001b[0mdenom\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mmax_exp_avg_sq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mmath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbias_correction2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgroup\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'eps'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 103\u001b[0;31m                     \u001b[0mdenom\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mexp_avg_sq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mmath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbias_correction2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgroup\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'eps'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    104\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m                 \u001b[0mstep_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgroup\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'lr'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mbias_correction1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]},{"cell_type":"code","metadata":{"id":"KfDT9o0tlWdF","colab_type":"code","outputId":"2380ebcb-1abf-4a23-c6ef-8b4ec2e76dd9","executionInfo":{"status":"ok","timestamp":1575369017880,"user_tz":-540,"elapsed":2319,"user":{"displayName":"M K","photoUrl":"","userId":"05537230611998731047"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["test_num = len(test)\n","a = 0\n","with torch.no_grad():\n","  for idx, batch in enumerate(test_iter):\n","    text1_tensor = batch.Text1[0]\n","    text2_tensor = batch.Text2[0]\n","    label_tensor = batch.Label\n","    \n","    state1 = model1(text1_tensor).squeeze()\n","    state2 = model2(text2_tensor).squeeze()\n","    score = merge(state1, state2)\n","    \n","    _, pred = torch.max(score, 1)\n","    for j, ans in enumerate(label_tensor):\n","      if pred[j].item() == ans.item():\n","        a += 1\n","\n","print(\"predict : \", a / test_num)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["predict :  0.7398208469055375\n"],"name":"stdout"}]}]}