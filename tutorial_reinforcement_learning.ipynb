{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"tutorial_reinforcement_learning.ipynb","provenance":[],"authorship_tag":"ABX9TyN9KfFxPWythfkcJc12YyKA"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":304},"id":"aqgQICcrWutR","executionInfo":{"status":"error","timestamp":1610786488296,"user_tz":-540,"elapsed":18186,"user":{"displayName":"M K","photoUrl":"","userId":"05537230611998731047"}},"outputId":"ec66a40a-732d-494e-bb24-47e8a0a47aa1"},"source":["#installing dependencies\n","!apt-get -qq -y install libcusparse8.0 libnvrtc8.0 libnvtoolsext1 > /dev/null\n","!ln -snf /usr/lib/x86_64-linux-gnu/libnvrtc-builtins.so.8.0 /usr/lib/x86_64-linux-gnu/libnvrtc-builtins.so\n","!apt-get -qq -y install xvfb freeglut3-dev ffmpeg> /dev/null\n","\n","!pip -q install gym\n","!pip -q install pyglet\n","!pip -q install pyopengl\n","!pip -q install pyvirtualdisplay\n","\n","# Start virtual display\n","from pyvirtualdisplay import Display\n","display = Display(visible=0, size=(1024, 768))\n","display.start()\n","import os\n","os.environ[\"DISPLAY\"] = \":\" + str(display.display) + \".\" + str(display.screen)"],"execution_count":24,"outputs":[{"output_type":"stream","text":["E: Unable to locate package libcusparse8.0\n","E: Couldn't find any package by glob 'libcusparse8.0'\n","E: Couldn't find any package by regex 'libcusparse8.0'\n","E: Unable to locate package libnvrtc8.0\n","E: Couldn't find any package by glob 'libnvrtc8.0'\n","E: Couldn't find any package by regex 'libnvrtc8.0'\n"],"name":"stdout"},{"output_type":"error","ename":"AttributeError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)","\u001b[0;32m<ipython-input-24-6f7ffd0b953f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0mdisplay\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menviron\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"DISPLAY\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\":\"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdisplay\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdisplay\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\".\"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdisplay\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscreen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;31mAttributeError\u001b[0m: 'Display' object has no attribute 'screen'"]}]},{"cell_type":"code","metadata":{"id":"vsF6kulTEpPi","executionInfo":{"status":"ok","timestamp":1610782173955,"user_tz":-540,"elapsed":4967,"user":{"displayName":"M K","photoUrl":"","userId":"05537230611998731047"}}},"source":["import gym\n","import math\n","import random\n","import numpy as np\n","import matplotlib\n","import matplotlib.pyplot as plt\n","from collections import namedtuple\n","from itertools import count\n","from PIL import Image\n","\n","import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","import torch.nn.functional as F\n","import torchvision.transforms as T"],"execution_count":1,"outputs":[]},{"cell_type":"code","metadata":{"id":"GJrTDGU0FogC","executionInfo":{"status":"ok","timestamp":1610782216793,"user_tz":-540,"elapsed":775,"user":{"displayName":"M K","photoUrl":"","userId":"05537230611998731047"}}},"source":["env = gym.make('CartPole-v0').unwrapped\n","\n","is_ipython = 'inline' in matplotlib.get_backend()\n","if is_ipython:\n","  from IPython import display\n","\n","plt.ion()\n","\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"],"execution_count":3,"outputs":[]},{"cell_type":"code","metadata":{"id":"UPsjZflMGWpW","executionInfo":{"status":"ok","timestamp":1610782833991,"user_tz":-540,"elapsed":585,"user":{"displayName":"M K","photoUrl":"","userId":"05537230611998731047"}}},"source":["Transition = namedtuple('Transition', ('state', 'action', 'next_state', 'reward'))\n","\n","class ReplayMemory(object):\n","  def __init__(self, capacity):\n","    self.capacity = capacity\n","    self.memory = []\n","    self.position = 0\n","\n","  def push(self, *args):\n","    if len(self.memory) < self.capacity:\n","      self.memory.append(None)\n","    self.memory[self.position] = Transition(*args)\n","    self.position = (self.position + 1) % self.capacity\n","\n","  def sample(self, batch_size):\n","    return random.sample(self.memory, batch_size)\n","\n","  def __len__(self):\n","    return len(self.memory)"],"execution_count":11,"outputs":[]},{"cell_type":"code","metadata":{"id":"fsRq1ilYI4v4","executionInfo":{"status":"ok","timestamp":1610783718434,"user_tz":-540,"elapsed":797,"user":{"displayName":"M K","photoUrl":"","userId":"05537230611998731047"}}},"source":["class DQN(nn.Module):\n","  def __init__(self, h, w, outputs):\n","    super(DQN, self).__init__()\n","    self.conv1 = nn.Conv2d(3, 16, kernel_size=5, stride=2)\n","    self.bn1 = nn.BatchNorm2d(16)\n","    self.conv2 = nn.Conv2d(16, 32, kernel_size=5, stride=2)\n","    self.bn2 = nn.BatchNorm2d(32)\n","    self.conv3 = nn.Conv2d(32, 32, kernel_size=5, stride=2)\n","    self.bn3 = nn.BatchNorm2d(32)\n","\n","    def conv2d_size_out(size, kernel_size=5, stride=2):\n","      return (size - (kernel_size - 1) - 1) // stride + 1\n","    convw = conv2d_size_out(conv2d_size_out(conv2d_size_out(w)))\n","    convh = conv2d_size_out(conv2d_size_out(conv2d_size_out(h)))\n","    linear_input_size = convw * convh * 32\n","    self.head = nn.Linear(linear_input_size, outputs)\n","  \n","  def forward(self, x):\n","    x = F.relu(self.bn1(self.conv1(x)))\n","    x = F.relu(self.bn2(self.conv2(x)))\n","    x = F.relu(self.bn3(self.conv3(x)))\n","    return self.head(x.view(x.size(0), -1))"],"execution_count":13,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":396},"id":"Cs7x9RW1MQhn","executionInfo":{"status":"error","timestamp":1610786018995,"user_tz":-540,"elapsed":676,"user":{"displayName":"M K","photoUrl":"","userId":"05537230611998731047"}},"outputId":"bdf5d224-95f8-4d01-dc13-ee8048a81103"},"source":["resize = T.Compose([T.ToPILImage(),\n","                    T.Resize(40, interpolation=Image.CUBIC),\n","                    T.ToTensor()])\n","\n","\n","def get_cart_location(screen_width):\n","    world_width = env.x_threshold * 2\n","    scale = screen_width / world_width\n","    return int(env.state[0] * scale + screen_width / 2.0)  # MIDDLE OF CART\n","\n","def get_screen():\n","    # Returned screen requested by gym is 400x600x3, but is sometimes larger\n","    # such as 800x1200x3. Transpose it into torch order (CHW).\n","    screen = env.render(mode='rgb_array').transpose((2, 0, 1))\n","    # Cart is in the lower half, so strip off the top and bottom of the screen\n","    _, screen_height, screen_width = screen.shape\n","    screen = screen[:, int(screen_height*0.4):int(screen_height * 0.8)]\n","    view_width = int(screen_width * 0.6)\n","    cart_location = get_cart_location(screen_width)\n","    if cart_location < view_width // 2:\n","        slice_range = slice(view_width)\n","    elif cart_location > (screen_width - view_width // 2):\n","        slice_range = slice(-view_width, None)\n","    else:\n","        slice_range = slice(cart_location - view_width // 2,\n","                            cart_location + view_width // 2)\n","    # Strip off the edges, so that we have a square image centered on a cart\n","    screen = screen[:, :, slice_range]\n","    # Convert to float, rescale, convert to torch tensor\n","    # (this doesn't require a copy)\n","    screen = np.ascontiguousarray(screen, dtype=np.float32) / 255\n","    screen = torch.from_numpy(screen)\n","    # Resize, and add a batch dimension (BCHW)\n","    return resize(screen).unsqueeze(0).to(device)\n","\n","\n","env.reset()\n","plt.figure()\n","plt.imshow(get_screen().cpu().squeeze(0).permute(1, 2, 0).numpy(),\n","           interpolation='none')\n","plt.title('Example extracted screen')\n","plt.show()"],"execution_count":22,"outputs":[{"output_type":"error","ename":"NameError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-22-5bb6791e791e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 39\u001b[0;31m plt.imshow(get_screen().cpu().squeeze(0).permute(1, 2, 0).numpy(),\n\u001b[0m\u001b[1;32m     40\u001b[0m            interpolation='none')\n\u001b[1;32m     41\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtitle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Example extracted screen'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-22-5bb6791e791e>\u001b[0m in \u001b[0;36mget_screen\u001b[0;34m()\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0;31m# Returned screen requested by gym is 400x600x3, but is sometimes larger\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0;31m# such as 800x1200x3. Transpose it into torch order (CHW).\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m     \u001b[0mscreen\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrender\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'rgb_array'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m     \u001b[0;31m# Cart is in the lower half, so strip off the top and bottom of the screen\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscreen_height\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscreen_width\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscreen\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/gym/envs/classic_control/cartpole.py\u001b[0m in \u001b[0;36mrender\u001b[0;34m(self, mode)\u001b[0m\n\u001b[1;32m    172\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    173\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mviewer\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 174\u001b[0;31m             \u001b[0;32mfrom\u001b[0m \u001b[0mgym\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menvs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclassic_control\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mrendering\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    175\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mviewer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrendering\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mViewer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscreen_width\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscreen_height\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    176\u001b[0m             \u001b[0ml\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0mcartwidth\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcartwidth\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcartheight\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0mcartheight\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/gym/envs/classic_control/rendering.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m     \u001b[0;32mfrom\u001b[0m \u001b[0mpyglet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgl\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m \u001b[0;32mexcept\u001b[0m \u001b[0mImportError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m     raise ImportError('''\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pyglet/gl/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    233\u001b[0m \u001b[0;32melif\u001b[0m \u001b[0mcompat_platform\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'darwin'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    234\u001b[0m     \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mcocoa\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mCocoaConfig\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mConfig\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 235\u001b[0;31m \u001b[0;32mdel\u001b[0m \u001b[0mbase\u001b[0m  \u001b[0;31m# noqa: F821\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    236\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    237\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name 'base' is not defined"]},{"output_type":"display_data","data":{"text/plain":["<Figure size 432x288 with 0 Axes>"]},"metadata":{"tags":[]}}]}]}