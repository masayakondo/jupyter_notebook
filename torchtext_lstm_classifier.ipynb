{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"torchtext_lstm_classifier.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"iTVT3yCmccP1","colab_type":"code","outputId":"a92dc630-9e34-4178-caf8-d033bb55bb2f","executionInfo":{"status":"ok","timestamp":1574323447653,"user_tz":-540,"elapsed":27320,"user":{"displayName":"M K","photoUrl":"","userId":"05537230611998731047"}},"colab":{"base_uri":"https://localhost:8080/","height":122}},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n","\n","Enter your authorization code:\n","··········\n","Mounted at /content/drive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"aErRURdydAIX","colab_type":"code","colab":{}},"source":["# # MeCabをcolabで使えるようにする\n","# !apt install aptitude\n","# !aptitude install mecab libmecab-dev mecab-ipadic-utf8 git make curl xz-utils file -y\n","# !pip install mecab-python3"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"sfJH5WLmc2ib","colab_type":"code","colab":{}},"source":["import torchtext\n","from torchtext import data\n","from torchtext import datasets\n","from torchtext.vocab import FastText\n","from torchtext.vocab import GloVe\n","from torchtext.vocab import Vectors\n","\n","import torch.nn as nn\n","import torch.optim as optim\n","import torch.nn.functional as F\n","import torch\n","from torch.autograd import Variable\n","\n","import pickle\n","\n","# import MeCab\n","import re, os\n","from glob import glob\n","from sklearn.model_selection import train_test_split\n","from tqdm import tqdm\n","import linecache\n","import pandas as pd"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"oq5UV6TSdYkM","colab_type":"code","outputId":"7d682980-8946-4135-c174-b6d62564d4e4","executionInfo":{"status":"ok","timestamp":1573978432812,"user_tz":-540,"elapsed":2031,"user":{"displayName":"M K","photoUrl":"","userId":"05537230611998731047"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["drive_dir = \"drive/My Drive/Colab Notebooks/\"\n","livedoor_data_dir = drive_dir + \"livedoor_data/\"\n","word_embedding_dir = drive_dir + \"word_embedding_models/\"\n","\n","tagger = MeCab.Tagger(\"-Owakati\")\n","\n","def make_wakati(sentence):\n","    sentence = tagger.parse(sentence)\n","    sentence = re.sub(r'[0-9０-９a-zA-Zａ-ｚＡ-Ｚ]+', \" \", sentence)\n","    sentence = re.sub(r'[\\．_－―─！＠＃＄％＾＆\\-‐|\\\\＊\\“（）＿■×+α※÷⇒—●★☆〇◎◆▼◇△□(：〜～＋=)／*&^%$#@!~`){}［］…\\[\\]\\\"\\'\\”\\’:;<>?＜＞〔〕〈〉？、。・,\\./『』【】「」→←○《》≪≫\\n\\u3000]+', \"\", sentence)\n","    wakati = sentence.split(\" \")\n","    wakati = list(filter((\"\").__ne__, wakati))\n","    return wakati\n","\n","categories = [name for name in os.listdir(livedoor_data_dir + 'text') if os.path.isdir(livedoor_data_dir + \"text/\" +name)]\n","print(categories)\n","\n","# row = []\n","# for cat in categories:\n","#     path = livedoor_data_dir + \"text/\" + cat + \"/*.txt\"\n","#     files = glob(path)\n","#     for text_name in tqdm(files):\n","#         title = linecache.getline(text_name, 3)\n","#         tmp = [title, categories.index(cat)]\n","#         row.append(tmp)\n","# livedoor_df = pd.DataFrame(row, columns=[\"title\", \"category\"])\n","\n","# with open(livedoor_data_dir + \"livedoor_datasets.pickle\", 'wb') as w:\n","#     pickle.dump(livedoor_df, w)\n","\n","with open(livedoor_data_dir + \"livedoor_datasets.pickle\", 'rb') as f:\n","  livedoor_df = pickle.load(f)\n","\n","cat_idx = []\n","for row in livedoor_df.iterrows():\n","  cat = row[1]['category']\n","  idx = categories.index(cat)\n","  cat_idx.append(idx)\n","\n","join_df = pd.DataFrame(cat_idx, columns=['category_id'])\n","livedoor_df = pd.concat([livedoor_df, join_df], axis=1)\n","\n","train_df, test_df = train_test_split(livedoor_df[['title', 'category_id']], train_size=0.7)\n","\n","train_df.to_csv(livedoor_data_dir + 'train_ja.tsv', sep=\"\\t\", index=False, header=False)\n","test_df.to_csv(livedoor_data_dir + 'test_ja.tsv', sep=\"\\t\", index=False, header=False)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["['it-life-hack', 'kaden-channel', 'livedoor-homme', 'topic-news', 'peachy', 'sports-watch', 'dokujo-tsushin', 'smax', 'movie-enter']\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"PzFuuLPie26d","colab_type":"code","outputId":"bc0c4452-1a98-4877-94a6-1ff2d1e8075c","executionInfo":{"status":"ok","timestamp":1573978436908,"user_tz":-540,"elapsed":1607,"user":{"displayName":"M K","photoUrl":"","userId":"05537230611998731047"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["TEXT = data.Field(sequential=True, tokenize=make_wakati, lower=True, include_lengths=True, batch_first=True)\n","LABEL = data.Field(sequential=False, use_vocab=False)\n","\n","train, test = data.TabularDataset.splits(\n","        path=livedoor_data_dir, train='train_ja.tsv', test='test_ja.tsv', format='tsv',\n","        fields=[('Text', TEXT), ('Label', LABEL)])\n","\n","print(vars(train[0]))"],"execution_count":0,"outputs":[{"output_type":"stream","text":["{'Text': ['コス', 'プレイヤー', 'の', '応募', '作品', 'を', 'そのまま', 'アプリ', 'に', 'コスプレフォト', 'の', '世界', 'が', '楽しめる', 'コス', 'プレ', '時計', 'アプリ', 'アプリ'], 'Label': '7'}\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"7VOj84rmfD-D","colab_type":"code","colab":{}},"source":["japanese_fasttext_vectors = Vectors(name=word_embedding_dir + \"wiki.ja.vec\")\n","TEXT.build_vocab(train, vectors=japanese_fasttext_vectors, min_freq=1)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"Zs3a95R_jM5V","colab_type":"code","colab":{}},"source":["device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","train_iter, test_iter = data.Iterator.splits((train, test), batch_sizes=(100, 100), device=device, repeat=False,sort=False)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"sAlzI4V3pUWJ","colab_type":"code","colab":{}},"source":["class AttentionLSTMClassifier(nn.Module):\n","    def __init__(self, embedding_dim, hidden_dim, vocab_size, tag_size):\n","        super(AttentionLSTMClassifier, self).__init__()\n","        self.hidden_dim = hidden_dim\n","        self.embed = nn.Embedding(vocab_size, embedding_dim)\n","        self.embed.weight.data.copy_(TEXT.vocab.vectors)\n","        self.embed.requred_grad_ = False\n","        self.gru = nn.GRU(embedding_dim, hidden_dim, batch_first=True)\n","        self.hidden2tag = nn.Linear(hidden_dim, tag_size)\n","        self.softmax = nn.Softmax(dim=1)\n","        self.log_softmax = nn.LogSoftmax(dim=1)\n","\n","    def forward(self, sentence):\n","        embeds = self.embed(sentence)\n","        out, hs = self.gru(embeds)\n","\n","        s = torch.bmm(out, torch.transpose(out,1,2))\n","        attention_weight = self.softmax(s)\n","        c = torch.zeros(out.size()[0], 1, self.hidden_dim, device=device)\n","        for i in range(attention_weight.size()[2]):\n","          unsq_weight = attention_weight[:,:,i].unsqueeze(2)\n","          weighted_hs = out * unsq_weight\n","          weight_sum = torch.sum(weighted_hs, axis=1).unsqueeze(1)\n","          c = torch.cat([c, weight_sum], dim=1)\n","        c = c[:,1:,:]\n","        c = c.sum(dim=1)\n","\n","        tag_space = self.hidden2tag(c)\n","        tag_score = self.log_softmax(tag_space)\n","\n","        return tag_score, attention_weight\n","\n","\n","EMBEDDING_DIM = TEXT.vocab.vectors.size()[1]\n","HIDDEN_DIM = 128\n","VOCAB_SIZE = TEXT.vocab.vectors.size()[0]\n","TAG_SIZE = len(categories)\n","# to(device)でモデルがGPU対応する\n","model = AttentionLSTMClassifier(EMBEDDING_DIM, HIDDEN_DIM, VOCAB_SIZE, TAG_SIZE).to(device)\n","loss_function = nn.NLLLoss()\n","optimizer = optim.Adam(model.parameters(), lr=0.001)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"eG_0daOmnLSM","colab_type":"code","outputId":"b17643ef-e473-4e93-f32f-ff71ae1a2115","executionInfo":{"status":"error","timestamp":1573979348283,"user_tz":-540,"elapsed":33221,"user":{"displayName":"M K","photoUrl":"","userId":"05537230611998731047"}},"colab":{"base_uri":"https://localhost:8080/","height":787}},"source":["losses = []\n","for epoch in range(100):\n","    all_loss = 0\n","    correct = 0\n","    train_num = 0\n","    for idx, batch in enumerate(train_iter):\n","        batch_loss = 0\n","\n","        model.zero_grad()\n","        title_tensor = batch.Text[0]\n","        category_tensor = batch.Label\n","\n","        score, hs = model(title_tensor)\n","\n","        batch_loss = loss_function(score, category_tensor)\n","        batch_loss.backward()\n","        optimizer.step()\n","        \n","        _, predicts = torch.max(score, 1)\n","        for j, ans in enumerate(category_tensor):\n","            if predicts[j].item() == ans.item():\n","                correct += 1\n","        train_num += category_tensor.size()[0]\n","\n","\n","        all_loss += batch_loss.item()\n","    print(\"epoch\", epoch, \"\\t\" , \"loss\", all_loss, \"\\t\", \"acc\", correct / train_num)\n","    if all_loss < 0.1: break\n","print(\"done.\")"],"execution_count":0,"outputs":[{"output_type":"stream","text":["epoch 0 \t loss 204.69387102127075 \t acc 0.1654077086964943\n","epoch 1 \t loss 102.4802680015564 \t acc 0.2775518109626186\n","epoch 2 \t loss 91.43012070655823 \t acc 0.39105171411969786\n","epoch 3 \t loss 76.30656278133392 \t acc 0.5186906837110207\n","epoch 4 \t loss 59.62267470359802 \t acc 0.6292852992446252\n","epoch 5 \t loss 46.011005878448486 \t acc 0.705210149138098\n","epoch 6 \t loss 32.0744503736496 \t acc 0.7917877203176448\n","epoch 7 \t loss 23.487269461154938 \t acc 0.8562851055587837\n","epoch 8 \t loss 19.94648975133896 \t acc 0.8723610304086771\n","epoch 9 \t loss 13.742605410516262 \t acc 0.9178772031764478\n","epoch 10 \t loss 8.967100329697132 \t acc 0.9486732519852799\n","epoch 11 \t loss 10.866885278373957 \t acc 0.9304667828781716\n","epoch 12 \t loss 6.58900348842144 \t acc 0.9631996901026535\n","epoch 13 \t loss 3.450178973376751 \t acc 0.9843114468332365\n","epoch 14 \t loss 2.4140785094350576 \t acc 0.9908967654464459\n","epoch 15 \t loss 1.7827170873060822 \t acc 0.9941894247530505\n","epoch 16 \t loss 2.6162975020706654 \t acc 0.9877977919814062\n","epoch 17 \t loss 1.5316729368641973 \t acc 0.9938020530699206\n","epoch 18 \t loss 1.184492310276255 \t acc 0.9963199690102653\n","epoch 19 \t loss 1.2815965828485787 \t acc 0.9941894247530505\n","epoch 20 \t loss 0.799306652508676 \t acc 0.9976757699012202\n","epoch 21 \t loss 1.0132136077154428 \t acc 0.9967073406933953\n","epoch 22 \t loss 1.0752950930036604 \t acc 0.9951578539608754\n","epoch 23 \t loss 1.1600045796949416 \t acc 0.9963199690102653\n"],"name":"stdout"},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-65-edf72550ab44>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0mbatch_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscore\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcategory_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m         \u001b[0mbatch_loss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m    164\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    165\u001b[0m         \"\"\"\n\u001b[0;32m--> 166\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    167\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    168\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m     97\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m     98\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 99\u001b[0;31m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m    100\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]},{"cell_type":"code","metadata":{"id":"Z62kgaTevQXq","colab_type":"code","outputId":"21d936bc-a9b0-4fff-e3cf-2371a7005ee8","executionInfo":{"status":"ok","timestamp":1573979352072,"user_tz":-540,"elapsed":832,"user":{"displayName":"M K","photoUrl":"","userId":"05537230611998731047"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["test_num = len(test_df)\n","a = 0\n","with torch.no_grad():\n","    # title_batch, category_batch = train2batch(test_x, test_y)\n","\n","    # for i in range(len(title_batch)):\n","    for idx, batch in enumerate(test_iter):\n","        title_tensor = batch.Text[0] #torch.tensor(title_batch[i], device=device)\n","        category_tensor = batch.Label #torch.tensor(category_batch[i], device=device)\n","\n","        score, hs = model(title_tensor)\n","        _, predicts = torch.max(score, 1)\n","        for j, ans in enumerate(category_tensor):\n","            if predicts[j].item() == ans.item():\n","                a += 1\n","print(\"predict : \", a / test_num)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["predict :  0.6398553999096249\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"5tH_XWPoe0X3","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]}]}