{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Transformer.ipynb","provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"Ksc_mgYawBj5","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":122},"outputId":"8d8a7258-a9f3-4ff5-e65a-870d238f6804","executionInfo":{"status":"ok","timestamp":1577540146494,"user_tz":-540,"elapsed":26487,"user":{"displayName":"M K","photoUrl":"","userId":"05537230611998731047"}}},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n","\n","Enter your authorization code:\n","··········\n","Mounted at /content/drive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"_pwYEtNrwd6C","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":51},"outputId":"04ab2346-727d-4b7d-ebcf-8f53cfbd22af","executionInfo":{"status":"ok","timestamp":1577540579462,"user_tz":-540,"elapsed":1724,"user":{"displayName":"M K","photoUrl":"","userId":"05537230611998731047"}}},"source":["import torchtext\n","from torchtext import data\n","from torchtext import datasets\n","from torchtext.vocab import GloVe\n","from torchtext.vocab import Vectors\n","\n","import torch.nn as nn\n","import torch.optim as optim\n","import torch.nn.functional as F\n","import torch\n","\n","from itertools import chain\n","\n","import pickle\n","\n","import numpy as np\n","import math\n","\n","\n","import re\n","import os\n","from sklearn.model_selection import train_test_split\n","import pandas as pd\n","\n","import itertools\n","import random\n","from IPython.display import display, HTML\n","\n","import nltk\n","from nltk import stem\n","nltk.download('punkt')\n","\n","def nltk_analyzer(text):\n","    stemmer = stem.LancasterStemmer()\n","    text = re.sub(re.compile(r'[!-\\/:-@[-`{-~]'), ' ', text)\n","    text = stemmer.stem(text)\n","    text = text.replace('\\n', '') # 改行削除\n","    text = text.replace('\\t', '') # タブ削除\n","    morph = nltk.word_tokenize(text)\n","    return morph"],"execution_count":8,"outputs":[{"output_type":"stream","text":["[nltk_data] Downloading package punkt to /root/nltk_data...\n","[nltk_data]   Package punkt is already up-to-date!\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"-q3_s8sdwfQa","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"outputId":"6cd83e4c-b4ec-4898-9964-3b8d3a1bcacc","executionInfo":{"status":"ok","timestamp":1577540301443,"user_tz":-540,"elapsed":106679,"user":{"displayName":"M K","photoUrl":"","userId":"05537230611998731047"}}},"source":["imdb_dir = \"drive/My Drive/Colab Notebooks/imdb_datasets/\"\n","word_embedding_dir = \"drive/My Drive/Colab Notebooks/word_embedding_models/\"\n","\n","with open(imdb_dir + 'train_df.pickle', 'rb') as f:\n","    train_df = pickle.load(f)\n","with open(imdb_dir + 'test_df.pickle', 'rb') as f:\n","    test_df = pickle.load(f)\n","\n","col = ['text', 'label_id']\n","train_df[col].to_csv(imdb_dir + \"train.tsv\", sep=\"\\t\", index=None, header=False)\n","test_df[col].to_csv(imdb_dir + \"test.tsv\", sep=\"\\t\", index=None, header=False)\n","\n","TEXT = data.Field(sequential=True, tokenize=nltk_analyzer, lower=True, include_lengths=True, batch_first=True, fix_length=300)\n","LABEL = data.Field(sequential=False, use_vocab=False, is_target=True)\n","\n","train, test = data.TabularDataset.splits(\n","      path=imdb_dir, train='train.tsv', test='test.tsv', format='tsv',\n","      fields=[('Text', TEXT), ('Label', LABEL)])\n","\n","glove_vectors = Vectors(name=word_embedding_dir + \"glove.6B.200d.txt\")\n","TEXT.build_vocab(train, test, vectors=glove_vectors, min_freq=1)"],"execution_count":3,"outputs":[{"output_type":"stream","text":["100%|█████████▉| 399932/400000 [00:25<00:00, 15969.63it/s]"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"Qtn2QhPeg8Qe","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":297},"outputId":"978ec998-2770-44ed-ed05-042193d59d09","executionInfo":{"status":"ok","timestamp":1577540306413,"user_tz":-540,"elapsed":1897,"user":{"displayName":"M K","photoUrl":"","userId":"05537230611998731047"}}},"source":["import seaborn as sns\n","length = []\n","for i in range(len(train)):\n","  length.append(len(train[i].Text))\n","df = pd.DataFrame(length, columns=['len'])\n","df.describe()"],"execution_count":4,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>len</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>count</th>\n","      <td>25000.000000</td>\n","    </tr>\n","    <tr>\n","      <th>mean</th>\n","      <td>242.392720</td>\n","    </tr>\n","    <tr>\n","      <th>std</th>\n","      <td>180.022367</td>\n","    </tr>\n","    <tr>\n","      <th>min</th>\n","      <td>10.000000</td>\n","    </tr>\n","    <tr>\n","      <th>25%</th>\n","      <td>132.000000</td>\n","    </tr>\n","    <tr>\n","      <th>50%</th>\n","      <td>181.000000</td>\n","    </tr>\n","    <tr>\n","      <th>75%</th>\n","      <td>295.000000</td>\n","    </tr>\n","    <tr>\n","      <th>max</th>\n","      <td>2525.000000</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                len\n","count  25000.000000\n","mean     242.392720\n","std      180.022367\n","min       10.000000\n","25%      132.000000\n","50%      181.000000\n","75%      295.000000\n","max     2525.000000"]},"metadata":{"tags":[]},"execution_count":4}]},{"cell_type":"code","metadata":{"id":"Dmv7WCPlwkMf","colab_type":"code","colab":{}},"source":["device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","\n","BATCH_SIZE=100\n","EMBEDDING_DIM = 200\n","LSTM_DIM = 128\n","VOCAB_SIZE =TEXT.vocab.vectors.size()[0]\n","TAG_SIZE = 2\n","MAX_LEN = 300\n","\n","# WordEmbedding層\n","class WordEmbedding(nn.Module):\n","  def __init__(self, embedding_dim, vocab_size):\n","    super(WordEmbedding, self).__init__()\n","    self.word_embeddings = nn.Embedding(vocab_size, embedding_dim)\n","    self.word_embeddings.weight.data.copy_(TEXT.vocab.vectors)\n","    self.word_embeddings.requires_grad_ = False\n","\n","  def forward(self, sentence):\n","    embeds = self.word_embeddings(sentence)\n","    return embeds\n","\n","# PositionalEncoder層\n","class PositionalEncoder(nn.Module):\n","  def __init__(self, embedding_dim, max_len):\n","    super(PositionalEncoder, self).__init__()\n","    self.embedding_dim = embedding_dim\n","    pe = torch.zeros(max_len, embedding_dim).to(device)\n","\n","    for pos in range(max_len):\n","      for i in range(0, embedding_dim, 2):\n","        pe[pos, i] = math.sin(pos / (10000 ** ((2 * i)/embedding_dim)))\n","        pe[pos, i + 1] = math.cos(pos / (10000 ** ((2 * (i + 1))/embedding_dim)))\n","    self.pe = pe.unsqueeze(0)\n","    self.pe.requires_grad_ = False\n","\n","  def forward(self, embeds):\n","    ret = math.sqrt(self.embedding_dim)*embeds + self.pe\n","    return ret\n","\n","\n","\n","embedding = WordEmbedding(EMBEDDING_DIM, VOCAB_SIZE).to(device)\n","positionalEncoder = PositionalEncoder(EMBEDDING_DIM, MAX_LEN).to(device)\n","loss_function = nn.NLLLoss()\n","\n","# optimizer = optim.Adam(chain(encoder.parameters(), classifier.parameters()), lr=0.001)\n","\n","train_iter, test_iter = data.Iterator.splits((train, test), batch_sizes=(BATCH_SIZE, BATCH_SIZE), device=device, repeat=False, sort=False)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"VRDo2BGAxjMN","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":68},"outputId":"f83f023f-980f-4780-d610-2538da19fa1f","executionInfo":{"status":"ok","timestamp":1577540917244,"user_tz":-540,"elapsed":1694,"user":{"displayName":"M K","photoUrl":"","userId":"05537230611998731047"}}},"source":["losses = []\n","for epoch in range(1):\n","    all_loss = 0\n","    for idx, batch in enumerate(train_iter):\n","        batch_loss = 0\n","        embedding.zero_grad()\n","\n","        text_tensor = batch.Text[0] # (b, s)\n","        print(text_tensor.size())\n","        label_tensor = batch.Label\n","\n","        embeds = embedding(text_tensor) # (b, s, d)\n","        print(embeds.size())\n","\n","        pe = positionalEncoder(embeds)\n","        print(pe.size())\n","\n","        break\n","    break"],"execution_count":16,"outputs":[{"output_type":"stream","text":["torch.Size([100, 300])\n","torch.Size([100, 300, 200])\n","torch.Size([100, 300, 200])\n"],"name":"stdout"}]}]}